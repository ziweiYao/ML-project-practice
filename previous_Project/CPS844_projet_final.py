# -*- coding: utf-8 -*-
"""844_projet.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1q1rsiWSQcVNIQNOIz4tivi9eD3QZHA8P
"""

import pandas as pd
import numpy as np
import seaborn as sns
from sklearn.cluster import KMeans
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.decomposition import PCA
from sklearn.model_selection import KFold, cross_val_score
from sklearn.svm import SVR
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import Lasso
from sklearn.model_selection import GridSearchCV

# Load dataset
df = pd.read_csv("Sleep_health_and_lifestyle_dataset.csv")
#print(df.head())


#------------------
#  Preprocessing
#------------------
# dropping Person ID attribute
df = df.drop(columns=['Person ID'], errors='ignore')

# Gender: Map 'Male' to 0 and 'Female' to 1.
gender_mapping = {'Male': 0, 'Female': 1}
df['Gender'] = df['Gender'].map(gender_mapping)

# BMI Category: Map 'Normal' to 1, 'Overweight' to 2, and 'Obese' to 3.
bmi_mapping = {'Normal': 1, 'Normal Weight' : 1, 'Overweight': 2, 'Obese': 3}
df['BMI Category'] = df['BMI Category'].map(bmi_mapping)

# Occupation: Map occupations to numbers.
# Note: 'Sales Representative' and 'Sales Person' are merged into the same category.
occupation_mapping = {
    'Engineer': 1,
    'Software Engineer': 2,
    'Sales Representative': 3,
    'Salesperson': 3,
    'Doctor': 4,
    'Nurse': 5,
    'Teacher': 6,
    'Accountant': 7,
    'Scientist': 8,
    'Lawyer': 9,
    'Manager': 10
}
df['Occupation'] = df['Occupation'].map(occupation_mapping)

# Clean the 'Sleep Disorder' column: strip whitespace and standardize the case
df['Sleep Disorder'] = df['Sleep Disorder'].astype(str).str.strip().str.title()

# Sleep Disorder: Map 'None' to 0, 'Sleep Apnea' to 1, and 'insomnia' to 2.
sleep_disorder_mapping = {'Sleep Apnea': 1, 'Insomnia': 2, 'Nan': 0}
df['Sleep Disorder'] = df['Sleep Disorder'].map(sleep_disorder_mapping)

# Loop over the DataFrame indices to update the Blood Pressure column
for idx in df.index:
    bp = df.at[idx, 'Blood Pressure']
    # Split the string and take the systolic value (first number)
    systolic = bp.split('/')[0]
    # Update the column with the systolic value as an integer
    df.at[idx, 'Blood Pressure'] = int(systolic)

#print(df.head())

# ------------------
#  Discretization
#-------------------
# List of attributes to discretize
attributes = ['Age', 'Sleep Duration', 'Quality of Sleep',
              'Physical Activity Level', 'Stress Level', 'Blood Pressure',
              'Heart Rate', 'Daily Steps']

# Choose the number of clusters for discretization, k = 3
num_clusters = 5


# Apply K-means discretization for each attribute individually
for attr in attributes:
    # Reshape the column into a 2D array (KMeans expects 2D input)
    values = df[attr].values.reshape(-1, 1)

    # Initialize and fit KMeans
    kmeans = KMeans(n_clusters=num_clusters, random_state=42)
    cluster_labels = kmeans.fit_predict(values)

    # Get cluster centers and sort them in ascending order
    centers = kmeans.cluster_centers_.flatten()
    sorted_idx = np.argsort(centers)

    # Create a mapping from original label to a new ordered label
    mapping = {old_label: new_label for new_label, old_label in enumerate(sorted_idx)}

    # Apply the mapping to reassign the labels in an ordered way
    ordered_labels = np.array([mapping[label] for label in cluster_labels])

    # Create a new column with the ordered discretized values
    df[attr] = ordered_labels


# Check the first few rows to verify the new discretized columns
#print(df.head(100))

# Compute the correlation matrix for the entire DataFrame
corr_matrix = df.corr()

# Set up the matplotlib figure
plt.figure(figsize=(12, 10))

# Draw the heatmap with the correlation matrix
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=".2f")

plt.title("Correlation Heatmap of Sleep Study Attributes")
plt.show()

#---------------------------
# 1st run: Linear Regression
#---------------------------
# Define the target variable
target = 'Quality of Sleep'

# Define predictors by dropping the target from the DataFrame
X = df.drop(columns=[target])
y = df[target]

# Split the data into training and testing sets (70% train, 30% test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Initialize and fit the Linear Regression model
model = LinearRegression()
model.fit(X_train, y_train)

# Predict the target on test set
y_pred = model.predict(X_test)

# Evaluate the model's performance
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

# Scatter plot of actual vs. predicted sleep quality for the test set
plt.figure(figsize=(8, 6))
plt.scatter(y_test, y_pred, alpha=0.7, label='Data Points')
# Plot the ideal line: where prediction equals actual value
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linestyle='--', label='Ideal Fit (y=x)')
plt.xlabel("Actual Quality of Sleep")
plt.ylabel("Predicted Quality of Sleep")
plt.title("Linear Regression: Actual vs. Predicted Sleep Quality")
plt.legend()
plt.show()

print("Linear Regression Results:")
print("Mean Squared Error:", mse)
print("R2 Score:", r2)

from sklearn.svm import SVR
from sklearn.metrics import mean_squared_error, r2_score

#-------------------------------------------
# 2nd Run: SVR with discretized values
#-------------------------------------------

# Define predictors and target (Quality of Sleep is our regression target)
X = df.drop(columns=['Quality of Sleep'])
y = df['Quality of Sleep']

# Split the dataset into training and testing sets (70% train, 30% test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Initialize and fit the SVR model (using RBF kernel here)
svr_model = SVR(kernel='rbf', C=1.0, epsilon=0.1)
svr_model.fit(X_train, y_train)

# Predict on the test set
y_pred = svr_model.predict(X_test)

# Compute evaluation metrics
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

# Plot Actual vs. Predicted Quality of Sleep
plt.figure(figsize=(8, 6))
plt.scatter(y_test, y_pred, alpha=0.7, label='Data Points')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', label='Ideal Fit (y=x)')
plt.xlabel("Actual Quality of Sleep")
plt.ylabel("Predicted Quality of Sleep")
plt.title("SVR: Actual vs. Predicted Quality of Sleep")
plt.legend()
plt.show()

print("SVR Results:")
print("Mean Squared Error:", mse)
print("R2 Score:", r2)

#======================================
# Run 2-1: SVR with minimal Pre-processing
#======================================
# the point is try to use as continuous valued attributes instead

# Load dataset again
df_minimal = pd.read_csv("Sleep_health_and_lifestyle_dataset.csv")

#-------------------------------
# Minimal Preprocessing for SVR
#-------------------------------

# Drop 'Person ID'
df_minimal = df_minimal.drop(columns=['Person ID'], errors='ignore')

# Map Gender: 'Male' -> 0, 'Female' -> 1
gender_mapping = {'Male': 0, 'Female': 1}
df_minimal['Gender'] = df_minimal['Gender'].map(gender_mapping)

# Map BMI Category: 'Normal' and 'Normal Weight' -> 1, 'Overweight' -> 2, 'Obese' -> 3
bmi_mapping = {'Normal': 1, 'Normal Weight': 1, 'Overweight': 2, 'Obese': 3}
df_minimal['BMI Category'] = df_minimal['BMI Category'].map(bmi_mapping)

# Map Occupation to numbers (merging Sales Representative and Salesperson)
occupation_mapping = {
    'Engineer': 1,
    'Software Engineer': 2,
    'Sales Representative': 3,
    'Salesperson': 3,
    'Doctor': 4,
    'Nurse': 5,
    'Teacher': 6,
    'Accountant': 7,
    'Scientist': 8,
    'Lawyer': 9,
    'Manager': 10
}
df_minimal['Occupation'] = df_minimal['Occupation'].map(occupation_mapping)

# Clean the 'Sleep Disorder' column and map its values
df_minimal['Sleep Disorder'] = df_minimal['Sleep Disorder'].astype(str).str.strip().str.title()
sleep_disorder_mapping = {'Sleep Apnea': 1, 'Insomnia': 2, 'Nan': 0}
df_minimal['Sleep Disorder'] = df_minimal['Sleep Disorder'].map(sleep_disorder_mapping)

# Process Blood Pressure: extract systolic if value is a string
for idx in df_minimal.index:
    bp = df_minimal.at[idx, 'Blood Pressure']
    if isinstance(bp, str):
        systolic = bp.split('/')[0]
        df_minimal.at[idx, 'Blood Pressure'] = int(systolic)

# We leave "Sleep Duration" and "Quality of Sleep" as continuous variables.
# "Quality of Sleep" is our target and remains continuous.

#------------------
# Define Predictors and Target
#------------------
# Use all attributes except "Quality of Sleep" as predictors.
X = df_minimal.drop(columns=['Quality of Sleep'])
y = df_minimal['Quality of Sleep']

#------------------
# Feature Scaling
#------------------
# SVR is sensitive to feature scales, so we scale the predictors.
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

#------------------
# Train-Test Split
#------------------
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)

#------------------
# SVR Model Training and Evaluation
#------------------
svr_model = SVR(kernel='rbf', C=1.0, epsilon=0.1)
svr_model.fit(X_train, y_train)
y_pred = svr_model.predict(X_test)

# Calculate evaluation metrics
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

#------------------
# Plot: Actual vs. Predicted Quality of Sleep
#------------------
plt.figure(figsize=(8, 6))
plt.scatter(y_test, y_pred, alpha=0.7, label='Data Points')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', label='Ideal Fit (y=x)')
plt.xlabel("Actual Quality of Sleep")
plt.ylabel("Predicted Quality of Sleep")
plt.title("SVR: Actual vs. Predicted Quality of Sleep (Minimal Pre-processing)")
plt.legend()
plt.show()

print("SVR with Minimal Pre-processing Results:")
print("Mean Squared Error:", mse)
print("R2 Score:", r2)

#----------------------------------
# Cross-validation for SVR run 2-1
#----------------------------------

# Using the preprocessed minimal dataset from before
# Define predictors and target
X = df_minimal.drop(columns=['Quality of Sleep'])
y = df_minimal['Quality of Sleep']

# Feature Scaling (SVR is sensitive to feature scales)
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Initialize the SVR model (using RBF kernel)
svr_model = SVR(kernel='rbf', C=1.0, epsilon=0.1)

# Define cross-validation strategy: 5-Fold CV
cv = KFold(n_splits=5, shuffle=True, random_state=42)

# Compute cross-validated Mean Squared Error (note: cross_val_score returns negative MSE)
cv_mse = -cross_val_score(svr_model, X_scaled, y, scoring='neg_mean_squared_error', cv=cv)
cv_r2 = cross_val_score(svr_model, X_scaled, y, scoring='r2', cv=cv)

print("SVR Cross-Validation Results with Minimal Pre-processing:")
print("Average MSE:", np.mean(cv_mse))
print("Average R2:", np.mean(cv_r2))


#-------------------------------
# Cross-validation for SVR run 2
#-------------------------------

# Here, df is the fully preprocessed DataFrame using the original (normal) preprocessing,
# where "Quality of Sleep" has been discretized

# Define predictors and target (here, the target is binary due to discretization)
X_normal = df.drop(columns=['Quality of Sleep'])
y_normal = df['Quality of Sleep']

# Scale the predictors (SVR is sensitive to feature scales)
scaler = StandardScaler()
X_normal_scaled = scaler.fit_transform(X_normal)

# Initialize the SVR model (using RBF kernel)
svr_model_normal = SVR(kernel='rbf', C=1.0, epsilon=0.1)

# Define a 5-fold cross-validation strategy
cv = KFold(n_splits=5, shuffle=True, random_state=42)

# Compute cross-validated Mean Squared Error (negated, so we revert sign) and R2 score
cv_mse_normal = -cross_val_score(svr_model_normal, X_normal_scaled, y_normal, scoring='neg_mean_squared_error', cv=cv)
cv_r2_normal = cross_val_score(svr_model_normal, X_normal_scaled, y_normal, scoring='r2', cv=cv)

print("\n")
print("SVR Cross-Validation Results with Normal Pre-processing:")
print("Average MSE:", np.mean(cv_mse_normal))
print("Average R2:", np.mean(cv_r2_normal))

#--------------------------------------------
# Run 3: use decision tree to make regression
#-------------------------------------------

from sklearn.tree import DecisionTreeRegressor
df1 = df.head(375)
target = 'Quality of Sleep'
X = df1.drop(columns=[target])
y = df1[target]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Initialize the Decision Tree Regressor
regressor = DecisionTreeRegressor(random_state=42)

# Train the model
regressor.fit(X_train, y_train)

# Make predictions on the test set
y_pred = regressor.predict(X_test)

# Evaluate the model performance
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)


from sklearn.tree import plot_tree

plt.figure(figsize=(30, 25),  dpi=80)
plot_tree(regressor, feature_names=X.columns, filled=True, rounded=True,
          fontsize=11)
plt.title("Decision Tree Regressor")
plt.show()

#testing
for i in range(10):

    sample = X_test.iloc[i:i+1]
    predicted_label = regressor.predict(sample)[0]
    actual_label = y_test.iloc[i]
    print(f"sample {i+1}: predicted value = {predicted_label}, true label = {actual_label}")

print("Decision Tree Regression Results:")
print("Mean Squared Error:", mse)
print("R2 Score:", r2)

#--------------------------------------------
# 4th run: Random Forest regression model
#-------------------------------------------

# define target variable 'Quality of Sleep' and feature varaible（all columns except target）
target = 'Quality of Sleep'
X = df1.drop(columns=[target])
y = df1[target]

# split data in to 30% test 70% train
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Initialize the Random Forest Regressor(100 trees)
rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)

# Train the model
rf_regressor.fit(X_train, y_train)

# Make predictions on the test set
y_pred = rf_regressor.predict(X_test)

# Evaluate the model performance
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

# -------------------------------
# Comparison of pred and true label
# -------------------------------

plt.figure(figsize=(8, 6))
plt.scatter(y_test, y_pred, alpha=0.7, label='Data Points')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linestyle='--', label='Ideal Fit (y=x)')
plt.xlabel("Actual Quality of Sleep")
plt.ylabel("Predicted Quality of Sleep")
plt.title("Random Forest Regression: Actual vs. Predicted Quality of Sleep")
plt.legend()
plt.show()

print("Random Forest Regression Results:")
print("Mean Squared Error:", mse)
print("R2 Score:", r2)

#--------------------------------------------
# 5th run: Lasso Regression (feature selection)
#-------------------------------------------


# Define predictors and target (using the continuous target for regression)
X = df.drop(columns=['Quality of Sleep'])
y = df['Quality of Sleep']

# Split the data into training and testing sets (70% train, 30% test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Initialize and fit Lasso Regression
lasso = Lasso(alpha=0.1, random_state=42)
lasso.fit(X_train, y_train)

# Predict on the test set
y_pred = lasso.predict(X_test)

# Evaluate the model
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print("Lasso Regression (Feature Selection) Results:")
print("Mean Squared Error:", mse)
print("R2 Score:", r2)

# Display the coefficients to see which features are selected (non-zero)
print("\nLasso Coefficients (Feature Selection):")
for feature, coef in zip(X.columns, lasso.coef_):
    print(f"{feature}: {coef}")

# Visualizing Lasso Coefficients
plt.figure(figsize=(10, 6))
plt.bar(X.columns, lasso.coef_)
plt.xlabel("Features")
plt.ylabel("Coefficient Value")
plt.title("Lasso Regression Coefficients")
plt.xticks(rotation=45)
plt.show()

# Plot: Actual vs. Predicted Quality of Sleep
plt.figure(figsize=(8, 6))
plt.scatter(y_test, y_pred, alpha=0.7, label='Data Points')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', label='Ideal Fit (y=x)')
plt.xlabel("Actual Quality of Sleep")
plt.ylabel("Predicted Quality of Sleep")
plt.title("Lasso Regression: Actual vs. Predicted Quality of Sleep")
plt.legend()
plt.show()

#--------------------------------------------
# Run 5-1: Lasso Regression with GridSearchCV
#-------------------------------------------


# Define predictors and target (assuming continuous target)
X = df.drop(columns=['Quality of Sleep'])
y = df['Quality of Sleep']

# Split dataset (70% train, 30% test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Hyperparameter tuning using GridSearchCV
param_grid = {'alpha': np.logspace(-4, 0, 50)}  # explore alphas from 0.0001 to 1.0
grid = GridSearchCV(Lasso(random_state=42, max_iter=5000), param_grid, cv=5, scoring='r2')
grid.fit(X_train, y_train)

# Best model from GridSearchCV
best_lasso = grid.best_estimator_
print("Best alpha:", grid.best_params_['alpha'])

# Predict on the test set
y_pred = best_lasso.predict(X_test)

# Evaluation metrics
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print("\nImproved Lasso Regression Results:")
print("Mean Squared Error:", mse)
print("R2 Score:", r2)

# Display the coefficients to see which features are selected (non-zero)
print("\nLasso Coefficients (Feature Selection):")
for feature, coef in zip(X.columns, lasso.coef_):
    print(f"{feature}: {coef}")

# Visualizing coefficients
plt.figure(figsize=(10, 6))
plt.bar(X.columns, best_lasso.coef_)
plt.xlabel("Features")
plt.ylabel("Coefficient Value")
plt.title("Improved Lasso Regression Coefficients")
plt.xticks(rotation=45)
plt.show()

# Plot actual vs predicted values
plt.figure(figsize=(8, 6))
plt.scatter(y_test, y_pred, alpha=0.7, label='Data Points')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', label='Ideal Fit (y=x)')
plt.xlabel("Actual Quality of Sleep")
plt.ylabel("Predicted Quality of Sleep")
plt.title("Improved Lasso Regression: Actual vs. Predicted Sleep Quality")
plt.legend()
plt.show()